{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment_2.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YXShjzY9EG__"},"outputs":[],"source":["import torch.nn as nn\n","import torch.utils.data\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import numpy as np\n","from PIL import Image\n","\n","from tqdm import tqdm\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, ):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(100, 64 * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(64 * 8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 4),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        # input data는 [batch size, 100, 1, 1]의 형태로 주어야합니다.\n","        return self.main(input)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, d=64):\n","      super(Discriminator, self).__init__()\n","\n","      self.layer1 = nn.Sequential(\n","          nn.Conv2d(in_channels=3, out_channels=d, kernel_size=4, stride=2, padding=1),\n","          nn.BatchNorm2d(d),\n","          nn.LeakyReLU(0.2, inplace=True),\n","      )\n","\n","      self.layer2 = nn.Sequential(\n","          nn.Conv2d(in_channels=d, out_channels=d*2, kernel_size=4, stride=2, padding=1),\n","          nn.BatchNorm2d(d*2),\n","          nn.LeakyReLU(0.2, inplace=True),\n","      )\n","\n","      self.layer3 = nn.Sequential(\n","          nn.Conv2d(in_channels=d*2, out_channels=d*4, kernel_size=4, stride=2, padding=1),\n","          nn.BatchNorm2d(d*4),\n","          nn.LeakyReLU(0.2, inplace=True),\n","      )\n","\n","      self.layer4 = nn.Sequential(\n","          nn.Conv2d(in_channels=d*4, out_channels=d*8, kernel_size=4, stride=2, padding=1),\n","          nn.BatchNorm2d(d*8),\n","          nn.LeakyReLU(0.2, inplace=True),\n","      )\n","\n","      self.layer5 = nn.Sequential(\n","          nn.Conv2d(in_channels=d*8, out_channels=1, kernel_size=4, stride=1, padding=0),\n","          nn.Sigmoid()\n","      )\n","    \n","    def forward(self, input):\n","      input = self.layer1(input)\n","      input = self.layer2(input)\n","      input = self.layer3(input)\n","      input = self.layer4(input)\n","      input = self.layer5(input)\n","      return input\n","\n","\n","if __name__ == \"__main__\":\n","    # 학습코드는 모두 여기서 작성해주세요\n","\n","    data_path = 'training_data/'\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5079152,0.42205644,0.37666804],[0.25580716, 0.23393774, 0.23002408])\n","    ])\n","\n","    dataset = datasets.ImageFolder(root=data_path,\n","                                   transform=transform,\n","                                   )\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    lr = 0.0002\n","    batch_size = 128\n","\n","    train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    generator = Generator().to(device)\n","    discriminator = Discriminator().to(device)\n","\n","    criterion = torch.nn.BCELoss()\n","    g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n","    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n","\n","    epochs = 30\n","    total_batch_num = len(train_dataloader)\n","\n","    for epoch in range(epochs):\n","      generator.train()\n","      discriminator.train()\n","\n","      avg_g_cost = 0\n","      avg_d_cost = 0\n","\n","      for step, batch in enumerate(train_dataloader):\n","        b_x = batch[0]\n","        num_img = len(b_x)\n","\n","        real_label = torch.ones((num_img, 1, 1, 1)).to(device)\n","        fake_label = torch.zeros((num_img, 1, 1, 1)).to(device)\n","\n","        real_logit = discriminator(b_x.to(device))\n","        d_real_loss = criterion(real_logit, real_label)\n","\n","        z = torch.randn((num_img, 100, 1, 1), requires_grad = False).to(device)\n","        fake_data = generator(z)\n","        fake_logit = discriminator(fake_data)\n","        d_fake_loss = criterion(fake_logit, fake_label)\n","        \n","        d_loss = d_real_loss + d_fake_loss\n","        d_optimizer.zero_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n","\n","        z = torch.randn((num_img, 100, 1, 1), requires_grad = False).to(device)\n","        fake_data = generator(z)\n","        fake_logit = discriminator(fake_data)\n","        g_loss = criterion(fake_logit, real_label)\n","\n","        g_optimizer.zero_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","\n","        avg_d_cost += d_loss\n","        avg_g_cost += g_loss\n","\n","      avg_d_cost /= total_batch_num\n","      avg_g_cost /= total_batch_num\n","\n","      print(\"Epoch: {}/{}, discriminator cost: {}, generator cost:{}\".format(epoch+1, epochs, avg_d_cost, avg_g_cost))\n","\n","    # FID score 측정에 사용할 fake 이미지를 생성하는 코드 입니다.\n","    # generator의 학습을 완료한 뒤 마지막에 실행하여 fake 이미지를 저장하시기 바랍니다.\n","    test_noise = torch.randn(3000, 100, 1, 1, device=device)\n","    with torch.no_grad():\n","        test_fake = generator(test_noise).detach().cpu()\n","\n","        for index, img in enumerate(test_fake):\n","            fake = np.transpose(img.detach().cpu().numpy(), [1, 2, 0])\n","            fake = (fake * 127.5 + 127.5).astype(np.uint8)\n","            im = Image.fromarray(fake)\n","            im.save(\"./fake_img/fake_sample{}.jpeg\".format(index))"]},{"cell_type":"code","source":["import os\n","import torch\n","\n","from pytorch_fid.fid_score import *\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n","\n","real_img_path = 'training_data/celeba/'\n","fake_img_path = 'fake_img/'\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","\n","if __name__ == \"__main__\":\n","    fid = calculate_fid_given_paths(\n","        paths=[real_img_path, fake_img_path],\n","        batch_size=128,\n","        device=device,\n","        dims=2048\n","    )\n","\n","    print(\"fid score : {}\".format(fid))\n"],"metadata":{"id":"1YZVprNUEL_9"},"execution_count":null,"outputs":[]}]}