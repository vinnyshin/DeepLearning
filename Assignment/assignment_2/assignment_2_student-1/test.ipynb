{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YXShjzY9EG__"},"outputs":[],"source":["import torch.nn as nn\n","import torch.utils.data\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import numpy as np\n","from PIL import Image\n","\n","from tqdm import tqdm\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","torch.cuda.manual_seed_all(0)"]},{"cell_type":"code","source":["!pip install -q wandb\n","import wandb\n","wandb.login()\n","\n","config = {\n","    \"dataset\": \"celeba\",\n","    \"gpu\": \"colab\",\n","    \"model\": \"GAN\",\n","}\n","\n","wandb.init(project=\"assignment_2\", config=config)\n","# api key 3a629afb6d101b0cc3a0123089694d3b03f196e3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"BlNCJweeDOnY","executionInfo":{"status":"ok","timestamp":1654408800620,"user_tz":-540,"elapsed":13103,"user":{"displayName":"신호중","userId":"00793881806762787903"}},"outputId":"da8a73d5-ef9b-4de9-9a41-a62e5dc87cd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinnyshin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.17"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220605_055952-270gd7q4</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/vinnyshin/assignment_2/runs/270gd7q4\" target=\"_blank\">bright-sound-4</a></strong> to <a href=\"https://wandb.ai/vinnyshin/assignment_2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/vinnyshin/assignment_2/runs/270gd7q4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7f9d72b1c4d0>"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hop8WujH-rqc","executionInfo":{"status":"ok","timestamp":1654408807580,"user_tz":-540,"elapsed":6968,"user":{"displayName":"신호중","userId":"00793881806762787903"}},"outputId":"33399b04-578f-4c31-8caa-d553e78c8be8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from zipfile import ZipFile\n","zip_path = '/content/drive/MyDrive/Univ/4-1/Deep Learning/Assignment/assignment_2/assignment_2_student-1/training_data/faces.zip'\n","faces_zip = ZipFile(zip_path, 'r')\n","faces_name_list = faces_zip.namelist()\n","\n","faces_PIL_img = []"],"metadata":{"id":"uCPm1cpy-9JV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 50초 걸림\n","for i in range(len(faces_name_list)):\n","  if i == 0: continue # faces_name_list[0] == celebe/\n","  _file = faces_zip.open(faces_name_list[i])\n","  img = Image.open(_file)\n","  faces_PIL_img.append(img)"],"metadata":{"id":"4g0RtHNEGvlu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","  def __init__(self, imgs, transforms=None):\n","      super().__init__()\n","      self.imgs = imgs\n","      self.transforms = transforms\n","\n","  def __len__(self):\n","      return len(self.imgs)\n","  \n","  def __getitem__(self, idx):\n","      image = self.imgs[idx]\n","\n","      if self.transforms:\n","        image = self.transforms(image)\n","\n","      return image"],"metadata":{"id":"_rIPEQpgilKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform = transforms.Compose([\n","#   transforms.ToTensor()\n","# ])"],"metadata":{"id":"849jevkUE2Gq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.array(transform(faces_PIL_img[0]))"],"metadata":{"id":"d9DgaXPmFA0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_meanRGB = [np.mean(np.array(transform(x)), axis=(1,2)) for x in faces_PIL_img]\n","# train_stdRGB = [np.std(np.array(transform(x)), axis=(1,2)) for x in faces_PIL_img]\n","\n","# train_meanR = np.mean([m[0] for m in train_meanRGB])\n","# train_meanG = np.mean([m[1] for m in train_meanRGB])\n","# train_meanB = np.mean([m[2] for m in train_meanRGB])\n","\n","# train_stdR = np.mean([s[0] for s in train_stdRGB])\n","# train_stdG = np.mean([s[1] for s in train_stdRGB])\n","# train_stdB = np.mean([s[2] for s in train_stdRGB])"],"metadata":{"id":"ltpV1GNhIE8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_meanRGB"],"metadata":{"id":"xKRCvzYaDR7Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(train_meanR)\n","# print(train_meanG)\n","# print(train_meanB)\n","# print(train_stdR)\n","# print(train_stdG)\n","# print(train_stdB)"],"metadata":{"id":"SiCIgvBZkTlH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.Normalize([0.5079152,0.42205644,0.37666804],[0.25580716, 0.23393774, 0.23002408])\n","])\n","\n","dataset = CustomDataset(faces_PIL_img, transforms=transform)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","lr = 0.0002\n","batch_size = 128\n","\n","train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"vjcfrhay8uXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","    def __init__(self, ):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(128, 64 * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(64 * 8),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 4),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64 * 2),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64 * 2, 64, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        # input data는 [batch size, 128, 1, 1]의 형태로 주어야합니다.\n","        return self.main(input)"],"metadata":{"id":"K8AKIjpzBSIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","      super(Discriminator, self).__init__()\n","      \n","      self.dropout = 0.3\n","      self.image_size = 64\n","      \n","      self.layer1 = nn.Sequential(\n","          nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n","          nn.BatchNorm2d(6),\n","          nn.LeakyReLU(0.2, inplace=True),\n","          nn.MaxPool2d(2),\n","          nn.Dropout(self.dropout)\n","      )\n","\n","      self.image_size = int(((self.image_size - 5) + 1) / 2)\n","\n","      self.layer2 = nn.Sequential(\n","          nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n","          nn.BatchNorm2d(16),\n","          nn.LeakyReLU(0.2, inplace=True),\n","          nn.MaxPool2d(2),\n","          nn.Dropout(self.dropout)\n","      )\n","      \n","      self.image_size = int(((self.image_size - 5) + 1) / 2)\n","\n","      self.layer3 = nn.Sequential(\n","          nn.Linear(in_features= 16 * self.image_size * self.image_size, out_features=1024, bias=True),\n","          nn.BatchNorm1d(1024),\n","          nn.LeakyReLU(0.2, inplace=True),\n","          nn.Dropout(self.dropout)\n","      )\n","\n","      self.layer4 = nn.Sequential(\n","          nn.Linear(in_features=1024, out_features=512, bias=True),\n","          nn.BatchNorm1d(512),\n","          nn.LeakyReLU(0.2, inplace=True),\n","          nn.Dropout(self.dropout)\n","      )\n","\n","      self.layer5 = nn.Sequential(\n","          nn.Linear(in_features=512, out_features=256, bias=True),\n","          nn.BatchNorm1d(256),\n","          nn.LeakyReLU(0.2, inplace=True),\n","          nn.Dropout(self.dropout)\n","      )\n","\n","      self.layer6 = nn.Sequential(\n","          nn.Linear(in_features= 256, out_features=1, bias=True),\n","          nn.Sigmoid(),\n","      )\n","      \n","      \n","      self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, input):\n","      input = self.layer1(input)\n","      input = self.layer2(input)\n","      input = input.view(-1, 16 * self.image_size * self.image_size)\n","      input = self.layer3(input)\n","      input = self.layer4(input)\n","      input = self.layer5(input)\n","      input = self.layer6(input)\n","      return input"],"metadata":{"id":"owtn7y0ZMnA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator = Generator().to(device)\n","discriminator = Discriminator().to(device)"],"metadata":{"id":"-zH4HA3T9fSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.BCELoss()\n","g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n","d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)"],"metadata":{"id":"AN_0sfOd9fHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import PIL\n","import matplotlib.pyplot as plt\n","\n","epochs = 200\n","total_batch_num = len(train_dataloader)\n","\n","for epoch in range(epochs):\n","  start = time.time()\n","  \n","  generator.train()\n","  discriminator.train()\n","\n","  avg_g_cost = 0\n","  avg_d_cost = 0\n","\n","  for step, batch in enumerate(train_dataloader):\n","    b_x = batch.to(device)\n","    # b_x = b_x.view(-1, 4096).to(device)\n","\n","    num_img = len(b_x)\n","\n","    real_label = torch.ones((num_img, 1)).to(device)\n","    fake_label = torch.zeros((num_img, 1)).to(device)\n","\n","    real_logit = discriminator(b_x)\n","    d_real_loss = criterion(real_logit, real_label)\n","    # Discriminator에게는 실제 사진에 대해서는 1에 근사하도록 Weight를 학습\n","\n","    # randn은 정규분포로 뽑아줘, uniform distribution은 rand함수\n","    z = torch.randn((num_img, 128, 1, 1), requires_grad=False).to(device)\n","    fake_data = generator(z)\n","\n","    fake_logit = discriminator(fake_data)\n","    d_fake_loss = criterion(fake_logit, fake_label)\n","    # 가짜 사진에 대해서는 0에 근사하도록 Weight를 학습\n","\n","    d_loss = d_real_loss + d_fake_loss\n","    d_optimizer.zero_grad()\n","    d_loss.backward()\n","    d_optimizer.step()\n","\n","    z = torch.randn((num_img, 128, 1, 1), requires_grad=False).to(device)\n","    fake_data = generator(z)\n","    fake_logit = discriminator(fake_data)\n","    g_loss = criterion(fake_logit, real_label)\n","    # Generator에게는 가짜 사진에 대해서 1에 근사하도록 Weight를 학습\n","\n","    g_optimizer.zero_grad()\n","    g_loss.backward()\n","    g_optimizer.step()\n","\n","    avg_d_cost += d_loss\n","    avg_g_cost += g_loss\n","\n","  avg_d_cost /= total_batch_num\n","  avg_g_cost /= total_batch_num\n","\n","  # observe fake images\n","  generator.eval()\n","  with torch.no_grad():\n","    z = torch.randn((64, 128, 1, 1), requires_grad=False).to(device)\n","    fake_data = generator(z)\n","    \n","    # fake_img = fake_data.detach().cpu().numpy().reshape(64, 3, 64, 64)\n","    fake_img = fake_data.detach().cpu()\n","\n","    transform = transforms.ToPILImage()\n","\n","    wandb.log({\n","        \"discriminator loss\": avg_d_cost,\n","        \"generator loss\": avg_g_cost,\n","        \"fake image\": [wandb.Image(transform(i)) for i in fake_img]\n","    })\n","  \n","  print(\"time :\", time.time() - start)\n","  print(f'Epoch: {epoch} \\t discriminator loss: {avg_d_cost} \\t generator loss: {avg_g_cost}')\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZP0TA0s5CZDL","outputId":"1f642139-50dc-453d-f450-fc6d9875eba1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time : 182.22099804878235\n","Epoch: 0 \t discriminator loss: 1.3772577047348022 \t generator loss: 0.7190449237823486\n","time : 180.89605855941772\n","Epoch: 1 \t discriminator loss: 1.313231110572815 \t generator loss: 0.7798025012016296\n","time : 180.9370458126068\n","Epoch: 2 \t discriminator loss: 0.7756184339523315 \t generator loss: 1.7067111730575562\n","time : 180.3532636165619\n","Epoch: 3 \t discriminator loss: 1.0931658744812012 \t generator loss: 1.3530759811401367\n","time : 180.7745921611786\n","Epoch: 4 \t discriminator loss: 1.2958927154541016 \t generator loss: 0.9882283210754395\n","time : 180.66463351249695\n","Epoch: 5 \t discriminator loss: 1.2792223691940308 \t generator loss: 0.9575323462486267\n","time : 180.68183183670044\n","Epoch: 6 \t discriminator loss: 1.315573811531067 \t generator loss: 0.8702454566955566\n","time : 180.79141998291016\n","Epoch: 7 \t discriminator loss: 1.3069047927856445 \t generator loss: 0.8807793855667114\n","time : 180.47492599487305\n","Epoch: 8 \t discriminator loss: 1.3038314580917358 \t generator loss: 0.8594396114349365\n","time : 180.84018540382385\n","Epoch: 9 \t discriminator loss: 1.2449796199798584 \t generator loss: 0.954852819442749\n","time : 180.65745425224304\n","Epoch: 10 \t discriminator loss: 1.2685056924819946 \t generator loss: 0.9547357559204102\n","time : 182.18455147743225\n","Epoch: 11 \t discriminator loss: 1.215531587600708 \t generator loss: 1.0063626766204834\n","time : 180.72059059143066\n","Epoch: 12 \t discriminator loss: 1.2124323844909668 \t generator loss: 1.0370632410049438\n","time : 180.58082389831543\n","Epoch: 13 \t discriminator loss: 1.2936638593673706 \t generator loss: 0.9113239645957947\n","time : 180.3565742969513\n","Epoch: 14 \t discriminator loss: 1.279112696647644 \t generator loss: 0.9161755442619324\n","time : 180.31349802017212\n","Epoch: 15 \t discriminator loss: 1.2191706895828247 \t generator loss: 0.9901014566421509\n","time : 180.41178822517395\n","Epoch: 16 \t discriminator loss: 1.2068407535552979 \t generator loss: 1.0421764850616455\n","time : 180.2761266231537\n","Epoch: 17 \t discriminator loss: 1.157855749130249 \t generator loss: 1.1197755336761475\n","time : 180.35926818847656\n","Epoch: 18 \t discriminator loss: 1.1693034172058105 \t generator loss: 1.1331745386123657\n","time : 180.48604655265808\n","Epoch: 19 \t discriminator loss: 1.184785008430481 \t generator loss: 1.0926897525787354\n","time : 180.21002960205078\n","Epoch: 20 \t discriminator loss: 1.1619929075241089 \t generator loss: 1.1036633253097534\n","time : 180.2370262145996\n","Epoch: 21 \t discriminator loss: 1.1747970581054688 \t generator loss: 1.117241621017456\n","time : 180.29650282859802\n","Epoch: 22 \t discriminator loss: 1.1890305280685425 \t generator loss: 1.09306800365448\n","time : 180.06943321228027\n","Epoch: 23 \t discriminator loss: 1.218285083770752 \t generator loss: 1.0080899000167847\n","time : 179.91822862625122\n","Epoch: 24 \t discriminator loss: 1.197702169418335 \t generator loss: 1.0539782047271729\n","time : 180.0555534362793\n","Epoch: 25 \t discriminator loss: 1.2246695756912231 \t generator loss: 0.9964286684989929\n","time : 179.9975323677063\n","Epoch: 26 \t discriminator loss: 1.2228169441223145 \t generator loss: 1.018621802330017\n","time : 180.1741166114807\n","Epoch: 27 \t discriminator loss: 1.241513729095459 \t generator loss: 0.9886758923530579\n","time : 180.2646188735962\n","Epoch: 28 \t discriminator loss: 1.2552992105484009 \t generator loss: 0.9778011441230774\n","time : 179.89114594459534\n","Epoch: 29 \t discriminator loss: 1.2445378303527832 \t generator loss: 0.982200026512146\n","time : 179.92582988739014\n","Epoch: 30 \t discriminator loss: 1.2198400497436523 \t generator loss: 0.9962222576141357\n","time : 179.93793106079102\n","Epoch: 31 \t discriminator loss: 1.2338786125183105 \t generator loss: 1.0086957216262817\n","time : 179.90492057800293\n","Epoch: 32 \t discriminator loss: 1.2289503812789917 \t generator loss: 0.9678594470024109\n","time : 179.9637885093689\n","Epoch: 33 \t discriminator loss: 1.095750331878662 \t generator loss: 1.205670714378357\n","time : 179.77592277526855\n","Epoch: 34 \t discriminator loss: 1.1252126693725586 \t generator loss: 1.1882998943328857\n","time : 180.09166264533997\n","Epoch: 35 \t discriminator loss: 1.231081247329712 \t generator loss: 1.0388950109481812\n","time : 179.77348279953003\n","Epoch: 36 \t discriminator loss: 1.2453428506851196 \t generator loss: 0.9768359661102295\n","time : 179.8359498977661\n","Epoch: 37 \t discriminator loss: 1.2224699258804321 \t generator loss: 0.9904888868331909\n","time : 180.1147084236145\n","Epoch: 38 \t discriminator loss: 1.2587660551071167 \t generator loss: 0.9422473311424255\n","time : 180.21472716331482\n","Epoch: 39 \t discriminator loss: 1.2445456981658936 \t generator loss: 0.957114577293396\n","time : 179.83576011657715\n","Epoch: 40 \t discriminator loss: 1.2367900609970093 \t generator loss: 0.9878233671188354\n","time : 179.7952389717102\n","Epoch: 41 \t discriminator loss: 1.2359470129013062 \t generator loss: 0.9880796074867249\n","time : 179.96173334121704\n","Epoch: 42 \t discriminator loss: 1.2276517152786255 \t generator loss: 1.003806710243225\n","time : 179.90955758094788\n","Epoch: 43 \t discriminator loss: 1.2539626359939575 \t generator loss: 0.9488485455513\n","time : 179.79181599617004\n","Epoch: 44 \t discriminator loss: 1.2305759191513062 \t generator loss: 0.960835337638855\n","time : 179.936420917511\n","Epoch: 45 \t discriminator loss: 1.2403415441513062 \t generator loss: 0.9544270038604736\n","time : 179.79290628433228\n","Epoch: 46 \t discriminator loss: 1.229866623878479 \t generator loss: 0.967444121837616\n","time : 179.81511807441711\n","Epoch: 47 \t discriminator loss: 1.2348908185958862 \t generator loss: 0.9790074825286865\n","time : 179.7687611579895\n","Epoch: 48 \t discriminator loss: 1.201274037361145 \t generator loss: 1.0294671058654785\n","time : 179.5465009212494\n","Epoch: 49 \t discriminator loss: 1.2113860845565796 \t generator loss: 1.0102185010910034\n","time : 179.67604994773865\n","Epoch: 50 \t discriminator loss: 1.2294001579284668 \t generator loss: 0.9682154059410095\n","time : 180.39701867103577\n","Epoch: 51 \t discriminator loss: 1.2197177410125732 \t generator loss: 0.9992745518684387\n","time : 179.6111717224121\n","Epoch: 52 \t discriminator loss: 1.2275409698486328 \t generator loss: 0.9992212653160095\n","time : 179.6920039653778\n","Epoch: 53 \t discriminator loss: 1.2241007089614868 \t generator loss: 0.9797682166099548\n","time : 181.46915483474731\n","Epoch: 54 \t discriminator loss: 1.2435964345932007 \t generator loss: 0.9471521973609924\n","time : 179.48295521736145\n","Epoch: 55 \t discriminator loss: 1.2400668859481812 \t generator loss: 0.9744157195091248\n","time : 179.81566452980042\n","Epoch: 56 \t discriminator loss: 1.2134555578231812 \t generator loss: 0.9994915723800659\n","time : 179.67808485031128\n","Epoch: 57 \t discriminator loss: 1.1954325437545776 \t generator loss: 1.0343834161758423\n","time : 179.62238931655884\n","Epoch: 58 \t discriminator loss: 1.2123570442199707 \t generator loss: 1.004022240638733\n","time : 179.4563009738922\n","Epoch: 59 \t discriminator loss: 1.1688458919525146 \t generator loss: 1.075632095336914\n","time : 179.6542558670044\n","Epoch: 60 \t discriminator loss: 1.1603621244430542 \t generator loss: 1.114039421081543\n","time : 179.6090292930603\n","Epoch: 61 \t discriminator loss: 1.2206677198410034 \t generator loss: 1.0356519222259521\n","time : 179.84416031837463\n","Epoch: 62 \t discriminator loss: 1.200419545173645 \t generator loss: 1.0096155405044556\n","time : 179.63921451568604\n","Epoch: 63 \t discriminator loss: 1.2244175672531128 \t generator loss: 1.0472902059555054\n","time : 179.38371562957764\n","Epoch: 64 \t discriminator loss: 1.1990246772766113 \t generator loss: 1.045931339263916\n","time : 179.49584007263184\n","Epoch: 65 \t discriminator loss: 1.2436193227767944 \t generator loss: 0.9813988208770752\n","time : 179.64226746559143\n","Epoch: 66 \t discriminator loss: 1.213195562362671 \t generator loss: 0.9961464405059814\n","time : 179.5018618106842\n","Epoch: 67 \t discriminator loss: 1.2268303632736206 \t generator loss: 0.9977080225944519\n","time : 179.2980670928955\n","Epoch: 68 \t discriminator loss: 1.2353624105453491 \t generator loss: 0.9941441416740417\n"]}]},{"cell_type":"code","source":["# FID score 측정에 사용할 fake 이미지를 생성하는 코드 입니다.\n","# generator의 학습을 완료한 뒤 마지막에 실행하여 fake 이미지를 저장하시기 바랍니다.\n","test_noise = torch.randn(3000, 100, 1, 1, device=device)\n","with torch.no_grad():\n","    test_fake = generator(test_noise).detach().cpu()\n","\n","    for index, img in enumerate(test_fake):\n","        fake = np.transpose(img.detach().cpu().numpy(), [1, 2, 0])\n","        fake = (fake * 127.5 + 127.5).astype(np.uint8)\n","        im = Image.fromarray(fake)\n","        im.save(\"./fake_img/fake_sample{}.jpeg\".format(index))"],"metadata":{"id":"FNxWetPb9MS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","\n","from pytorch_fid.fid_score import *\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n","\n","real_img_path = 'training_data/celeba/'\n","fake_img_path = 'fake_img/'\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","torch.cuda.manual_seed_all(0)\n","\n","if __name__ == \"__main__\":\n","    fid = calculate_fid_given_paths(\n","        paths=[real_img_path, fake_img_path],\n","        batch_size=128,\n","        device=device,\n","        dims=2048\n","    )\n","\n","    print(\"fid score : {}\".format(fid))\n"],"metadata":{"id":"1YZVprNUEL_9"},"execution_count":null,"outputs":[]}]}